{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marialago/AbstractArtWithDCGAN/blob/main/ArtWithDCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSd-eJrVA2tj"
      },
      "outputs": [],
      "source": [
        "# Bloco 1: Importações e Configuração\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "\n",
        "# --- CONFIGURAÇÃO ---\n",
        "IMAGE_SIZE = 64\n",
        "IMAGE_CHANNELS = 3\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 8000\n",
        "NOISE_DIM = 256\n",
        "EPOCHS = 1000\n",
        "GEN_LR = 2e-4\n",
        "DISC_LR = 1e-4\n",
        "ADAM_BETA_1 = 0.5\n",
        "OUTPUT_DIR = 'generated_images_new_dataset' # Diretório para salvar imagens geradas\n",
        "\n",
        "# Cria o diretório de saída se ele não existir\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "print(\"Configurações carregadas.\")\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco 2: Carregamento e Pré-processamento de Dados (Dataset do Kaggle)\n",
        "import tensorflow as tf\n",
        "\n",
        "# dataset_dir_path = 'kaggle_dataset/abstract_patterns'\n",
        "dataset_dir_path = 'kaggle_dataset/img' # Ajuste conforme necessário!\n",
        "\n",
        "def load_kaggle_dataset():\n",
        "    print(f\"Carregando imagens de: {dataset_dir_path}\")\n",
        "\n",
        "    # Verifica se o diretório existe\n",
        "    if not os.path.exists(dataset_dir_path) or not os.listdir(dataset_dir_path):\n",
        "         raise ValueError(f\"Diretório do dataset '{dataset_dir_path}' não encontrado ou vazio. \"\n",
        "                          \"Verifique o caminho e se o download/descompactação funcionou.\")\n",
        "\n",
        "\n",
        "    # labels=None e label_mode=None porque GANs são não supervisionadas\n",
        "    # shuffle=False aqui, vamos embaralhar depois da normalização\n",
        "    # batch_size=None para carregar tudo e depois aplicar map/batch, OU defina BATCH_SIZE direto\n",
        "    train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        dataset_dir_path,\n",
        "        labels=None, # Não precisamos de rótulos para GAN\n",
        "        label_mode=None,\n",
        "        image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        interpolation='nearest', # Ou 'bilinear'\n",
        "        batch_size=BATCH_SIZE, # Processa em lotes\n",
        "        shuffle=True # Pode embaralhar aqui ou depois\n",
        "    )\n",
        "\n",
        "    # Função para normalizar as imagens para o intervalo [-1, 1]\n",
        "    def normalize_img(image):\n",
        "        # As imagens carregadas por image_dataset_from_directory estão em [0, 255]\n",
        "        image = tf.cast(image, tf.float32)\n",
        "        image = (image - 127.5) / 127.5\n",
        "        return image\n",
        "\n",
        "    # Aplica a normalização a cada imagem no dataset\n",
        "    train_dataset = train_dataset.map(normalize_img,\n",
        "                                      num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Embaralha e otimiza o carregamento (prefetch)\n",
        "    # Se shuffle=True em image_dataset_from_directory, este shuffle pode ser redundante mas não prejudica\n",
        "    train_dataset = train_dataset.shuffle(BUFFER_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    print(\"Dataset do Kaggle carregado e pré-processado.\")\n",
        "    # Verifica um lote de exemplo (opcional)\n",
        "    for image_batch in train_dataset.take(1):\n",
        "        print(\"Forma do lote de imagens:\", image_batch.shape)\n",
        "        print(\"Valores min/max:\", tf.reduce_min(image_batch).numpy(), tf.reduce_max(image_batch).numpy())\n",
        "\n",
        "    return train_dataset\n",
        "\n",
        "# Carrega o dataset (substitui a chamada anterior)\n",
        "train_dataset = load_kaggle_dataset()\n"
      ],
      "metadata": {
        "id": "DhVnn7OTBFXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco 3: Modelo Gerador (Robusto - CORRIGIDO)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# (Certifique-se que NOISE_DIM, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS estão definidos)\n",
        "\n",
        "def make_robust_generator_model_corrected():\n",
        "    model = tf.keras.Sequential(name=\"Robust_Generator_Corrected\")\n",
        "\n",
        "    # Ponto de partida: Camada Densa e Reshape\n",
        "    start_h, start_w = IMAGE_SIZE // 8, IMAGE_SIZE // 8 # 8x8\n",
        "    model.add(layers.Dense(start_h * start_w * 1024, use_bias=False, input_shape=(NOISE_DIM,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Reshape((start_h, start_w, 1024)))\n",
        "    # Saída: (None, 8, 8, 1024)\n",
        "\n",
        "    # Bloco de Upsampling 1: 8x8 -> 16x16\n",
        "    model.add(layers.Conv2DTranspose(512, 5, strides=(2, 2), padding='same', use_bias=False))\n",
        "    # Saída: (None, 16, 16, 512)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Bloco de Upsampling 2: 16x16 -> 32x32\n",
        "    model.add(layers.Conv2DTranspose(256, 5, strides=(2, 2), padding='same', use_bias=False))\n",
        "    # Saída: (None, 32, 32, 256)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Bloco de Upsampling 3 (Final): 32x32 -> 64x64\n",
        "    # A camada final usa 'tanh' para mapear para [-1, 1]\n",
        "    model.add(layers.Conv2DTranspose(IMAGE_CHANNELS, 5, strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    # Saída: (None, 64, 64, IMG_CHANNELS)\n",
        "\n",
        "    # Verifica a forma final\n",
        "    assert model.output_shape == (None, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Cria o gerador robusto corrigido\n",
        "generator = make_robust_generator_model_corrected() # Use esta função\n",
        "print(\"Modelo Gerador Robusto (Corrigido) criado.\")\n",
        "generator.summary()\n"
      ],
      "metadata": {
        "id": "xwdygM2iBHDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco 4: Modelo Discriminador (Modificado - Kernel 4x4)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_modified_discriminator_model():\n",
        "    model = tf.keras.Sequential(name=\"Discriminator_SN_k4x4\", layers=[ # Nome atualizado\n",
        "        layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)),\n",
        "\n",
        "        # Bloco 1: 64x64 -> 32x32\n",
        "        # *** KERNEL 5x5 ***\n",
        "        layers.SpectralNormalization(\n",
        "            layers.Conv2D(64, 5, strides=(2, 2), padding='same')\n",
        "        ),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        # Bloco 2: 32x32 -> 16x16\n",
        "        # *** KERNEL 5x5 ***\n",
        "        layers.SpectralNormalization(\n",
        "            layers.Conv2D(128, 5, strides=(2, 2), padding='same')\n",
        "        ),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        # Bloco 3: 16x16 -> 8x8\n",
        "        # *** KERNEL 5x5 ***\n",
        "        layers.SpectralNormalization(\n",
        "            layers.Conv2D(256, 5, strides=(2, 2), padding='same')\n",
        "        ),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        # Bloco 4: 8x8 -> 4x4\n",
        "        # *** KERNEL 5x5 ***\n",
        "        layers.SpectralNormalization(\n",
        "            layers.Conv2D(512, 5, strides=(2, 2), padding='same')\n",
        "        ),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        # Final: Flatten e Dense(1) para logit\n",
        "        layers.Flatten(),\n",
        "        layers.SpectralNormalization(\n",
        "            layers.Dense(1)\n",
        "        )\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Cria o discriminador modificado\n",
        "discriminator = make_modified_discriminator_model() # Substitui o discriminador anterior\n",
        "print(\"Modelo Discriminador Modificado (Kernel 4x4, SN nativa) criado.\")\n",
        "discriminator.summary()\n"
      ],
      "metadata": {
        "id": "wEJKvBV0BINa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco 5: Funções de Perda e Otimizadores\n",
        "\n",
        "# Função de perda de entropia cruzada binária (adequada para classificação binária)\n",
        "# from_logits=True porque a saída do discriminador não tem ativação sigmoid\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output, smooth_factor=0.9): # Adiciona smooth_factor\n",
        "    # Label Smoothing: rótulo para reais é 0.9 em vez de 1.0\n",
        "    smooth_factor = 0.9\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output) * smooth_factor, real_output)\n",
        "    # Rótulo para falsos continua sendo 0.0\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "     # O gerador ainda quer que o discriminador pense que as fakes são reais (rótulo 1.0)\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# Otimizadores Adam para ajustar os pesos dos modelos\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=GEN_LR, beta_1=ADAM_BETA_1)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=DISC_LR, beta_1=ADAM_BETA_1)\n",
        "\n",
        "print(\"Funções de perda e otimizadores definidos.\")\n"
      ],
      "metadata": {
        "id": "6RHiUXzSBI9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco 6: Checkpointing (salvar o progresso)\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "print(f\"Checkpoint será salvo em: {checkpoint_dir}\")\n",
        "# Para restaurar o último checkpoint (se existir):\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "print(\"Checkpoint restaurado (se encontrado).\")\n"
      ],
      "metadata": {
        "id": "PP-PUrDgBJ_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco 7: Definição do Passo de Treinamento\n",
        "\n",
        "# @tf.function compila a função para um grafo TensorFlow, o que acelera a execução\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    # Gera um lote de vetores de ruído aleatório\n",
        "    noise = tf.random.normal([tf.shape(images)[0], NOISE_DIM])\n",
        "\n",
        "    # Usa GradientTape para registrar as operações para diferenciação automática\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Gera imagens falsas a partir do ruído\n",
        "        generated_images = generator(noise, training=True) # training=True ativa camadas como BatchNormalization e Dropout\n",
        "\n",
        "        # Obtém as previsões do discriminador para imagens reais e falsas\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        # Calcula as perdas do gerador e do discriminador\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # Calcula os gradientes das perdas em relação às variáveis treináveis dos modelos\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Aplica os gradientes aos otimizadores para atualizar os pesos dos modelos\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    # Retorna as perdas para monitoramento\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "print(\"Função de passo de treinamento definida.\")\n"
      ],
      "metadata": {
        "id": "P7qRgocfBK15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco 8: Função para Gerar e Salvar Imagens\n",
        "\n",
        "seed = tf.random.normal([16, NOISE_DIM]) # Gera 16 imagens para visualização\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "   # `training=False` para modo de inferência (importante para BN e Dropout, se houver)\n",
        "    predictions = model(test_input, training=False)\n",
        "    fig = plt.figure(figsize=(4, 4)) # Tamanho padrão 4x4\n",
        "\n",
        "    for i in range(predictions.shape[0]): # predictions.shape[0] == 16\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        # Denormaliza a imagem de [-1, 1] para [0, 1]\n",
        "        img_to_show = (predictions[i] + 1) / 2.0\n",
        "        plt.imshow(img_to_show)\n",
        "        plt.axis('off')\n",
        "\n",
        "    # Salva a figura no diretório de saída\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, 'image_at_epoch_{:04d}.png'.format(epoch)))\n",
        "    plt.close(fig) # Fecha a figura para liberar memória\n",
        "    # plt.show() # Opcional: exibe o plot diretamente no Colab (pode poluir a saída)\n",
        "\n",
        "print(\"Função para gerar e salvar imagens definida.\")\n"
      ],
      "metadata": {
        "id": "vY1WxIj1BL1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco 9: Função do Loop de Treinamento\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    print(\"Iniciando o treinamento...\")\n",
        "    gen_losses_history = []\n",
        "    disc_losses_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time() # Marca o tempo de início da época\n",
        "        gen_loss_epoch = []      # Lista para armazenar perdas do gerador na época\n",
        "        disc_loss_epoch = []     # Lista para armazenar perdas do discriminador na época\n",
        "\n",
        "        # Itera sobre os lotes do dataset\n",
        "        for batch_num, image_batch in enumerate(dataset):\n",
        "            g_loss, d_loss = train_step(image_batch) # Executa um passo de treinamento\n",
        "            gen_loss_epoch.append(g_loss.numpy())    # Armazena as perdas\n",
        "            disc_loss_epoch.append(d_loss.numpy())\n",
        "\n",
        "\n",
        "        # Gera e salva imagens de exemplo no final de cada época\n",
        "        generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "        # Salva o modelo (checkpoint) a cada 15 épocas\n",
        "        if (epoch + 1) % 15 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "            print(f\"Checkpoint salvo para a época {epoch + 1}\")\n",
        "\n",
        "        # Calcula a média das perdas da época\n",
        "        avg_gen_loss = np.mean(gen_loss_epoch)\n",
        "        avg_disc_loss = np.mean(disc_loss_epoch)\n",
        "        gen_losses_history.append(avg_gen_loss)\n",
        "        disc_losses_history.append(avg_disc_loss)\n",
        "\n",
        "        epoch_time = time.time() - start_time # Calcula o tempo da época\n",
        "\n",
        "        # Imprime o resumo da época\n",
        "        print(f'Época {epoch + 1}/{epochs} concluída em {epoch_time:.2f} seg')\n",
        "        print(f'  Perda Média Gerador: {avg_gen_loss:.4f}, Perda Média Discriminador: {avg_disc_loss:.4f}')\n",
        "\n",
        "    # Gera uma imagem final após a última época\n",
        "    generate_and_save_images(generator, epochs, seed)\n",
        "    print(\"Treinamento concluído.\")\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(gen_losses_history, label='Perda Gerador')\n",
        "    plt.plot(disc_losses_history, label='Perda Discriminador')\n",
        "    plt.title(\"Evolução das Perdas Durante o Treinamento\")\n",
        "    plt.xlabel(\"Épocas\")\n",
        "    plt.ylabel(\"Perda (Binary Cross-Entropy)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, \"loss_plot.png\"))\n",
        "    plt.show()\n",
        "\n",
        "print(\"Função de treinamento definida.\")\n"
      ],
      "metadata": {
        "id": "_8BeVqD1BMuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco 10: Executar o Treinamento\n",
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "QjwWJZcnBPqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco 11: Gerar uma Imagem Após o Treinamento\n",
        "\n",
        "num_samples = 32\n",
        "grid_size = int(num_samples**0.5) # Tamanho da grade para exibir as imagens\n",
        "\n",
        "sample_noise = tf.random.normal([num_samples, NOISE_DIM])\n",
        "generated_samples = generator(sample_noise, training=False)\n",
        "\n",
        "fig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size, grid_size))\n",
        "\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    img = (generated_samples[i] * 127.5 + 127.5).numpy().astype(\"uint8\")\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0LEfs526BQRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}